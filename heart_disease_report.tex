\documentclass{article}
\usepackage{graphicx}
\usepackage[margin=0.75in]{}
\begin{document}
\title{BIOS 611 Project Heart Disease Report}
\author{Z. Xie}
\date{October 29, 2021}
\maketitle
\section{Introduction}
In this project, our goal is to to accurately predict if a person has heart disease using a regression model with demographic information such as age and medical tests results such as serum cholesterol level. We hope our model can be used as a pre-testing tool for doctors to decide if further medical testing is necessary.\\

Throughout our analysis, we face two major challenges. The first one is to control the false negative rate (fnr) because telling a patient no further test is needed when he/she has heart disease can lead to fatal consequences and is therefore much more costly than false positives. Secondly, we need to limit to size of our model to ensure our model is realistic and interpretable for users such as doctors/patients. If our model is too large or complex, doctors would not be be able verify the model with their domain expertise and therefore the model would not trusted. However, in general, both controlling fnr and reducing model size can make it harder for the model to achieve high accuracy. Therefore, it is critical that we design our model structure and select model features intelligently to deal with these two challenges while moving toward our goal to make accurate predictions.\\

\section{Data Description}
The dataset we use was from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V attributed to four doctors: Andras Janosi, M.D (Hungarian Institute of Cardiology. Budapest co), William Steinbrunn, M.D (University Hospital, Zurich, Switzerland), Matthias Pfisterer, M.D (University Hospital, Basel, Switzerlan) and Robert Detrano, M.D. (V.A. Medical Center, Long Beach and Cleveland Clinic Foundation). We chose this dataset because it has both demographics information (age and sex) and medical test results (chest pain type, serum cholesterol level etc.).\\


Here is summary of the 14 attributes in the dataset as follows: \\
1. age:age in years  \\
2. sex: (1 for male, 0 for female)  \\
3. cp: chest pain type (4 values)  \\
4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)  \\
5. chol: serum cholesterol (in mg/dl)  \\
6. fbs: fasting blood sugar > 120 mg/dl (1 = true; 0 = false)  \\
7. restecg: resting electrocardiographic results (values 0,1,2)  \\
8. thalach: maximum heart rate achieved  \\
9. exang: exercise induced angina(1 = yes; 0 = no)  \\
10. oldpeak: ST depression induced by exercise relative to rest  \\
11. slope: the slope of the peak exercise ST segment(values 0,1,2)  \\
12. ca: number of major vessels (0-3) colored by flourosopy  \\
13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect  \\
14: Target (response): 0=no heart disease, 1=has heart disease  \\


In this dataset, our response variable is target. Prior to performing our data
analysis, we randomly selected 0.9 of the data as our training set and 0.1 of
the data as our validation set. The rest of 0.1 data will be our test set,
which will be used in the end to assess our model's predictive prowess.  \\

\section{EDA}
First we will perform some basic EDAs using our training set. We only included
a corrolgram in our report because it provided the most information for
our project while most of other plots are not very informative. \\

\includegraphics[width=0.8\textwidth]{figures/corrgram.png}\\

From the plot, we see the features with the highest correlations with target
are oldpeak, ca, exang, slope and thalach. And we also observe
there are some highly colinear variables such as oldpeak and slope,
However, since our research question focuses on prediction,
we will not explicitly deal with this problem in this report. \\

\section{Methodology}
For this report, we decided to use a logistic regression model and
to use forward BIC method to select the most relevant explanatory variables
and the interaction terms between two explanatory variables
with training set for our final regression model.
Then, to find the optimal decision boundary,
we used our final regression model to predict the validation set
and drew a fpr vs fnr curve using the predictions.
The final decision boundary was chosen
so that false positive rate (fpr) is minimized while keeping fnr under 0.05,
which we chose to be our target fnr.\\

We chose a logistic regression model because our response variable is binary
and we chose BIC because it finds the model that maximizes the likelihood
of the data (which is closely associated with higher accuracy)
while penalizing large models, Therefore it is ideal
to deal with the second challenge to limit the model size.
We chose forward method because it would be too computationally expensive
to perform exhaustive search. Even though forward method doesn't guarantee that
we would find the best model, it still finds a model with high performance
in general and hence we believe it serves as a valid alternative to exhaustive search.
The use of fpr vs fnr plot to find decision boundary is
to deal with first challenge of controlling fnr. The reasons for our choice
to use 0.05 as fnr cutoff and to use only interactions
between two explanatory variables will be discussed in the discussion section.\\

Using BIC, we decided that the most helpful features for our final model are
exang, oldpeak, cp, ca, thal, sex, thalach, restecg, ca:thal, oldpeak:ca, cp:ca,
exang:sex, exang:oldpeak, exang:cp, ca:restecg, oldpeak:sex, cp:thalach (17 in total).
Many of the features selected by our model also appear to have a high correlation
with target in the corrolgram during EDA.\\


Then to decide on the optimal decision boundary, we used our regression model
to predict the validation set and drew a tpr vs tnr curve using the predictions:\\

\includegraphics[width=0.8\textwidth]{figures/roc.png}\\

By observing the tpr vs tnr curve, we found that the best fpr
we can achieve while controlling fnr to be under 0.05
is around 0.19 when the cutoff is 0.31. The cutoff also happens to be
the decision boundary that maximizes the overall accuracy.\\


Hence we decided that our final model would be a logistical regression model
with exang, oldpeak, cp, ca, thal, sex, thalach, restecg, ca:thal, oldpeak:ca,
cp:ca, exang:sex, exang:oldpeak, exang:cp, ca:restecg, oldpeak:sex and cp:thalach
as our features and 0.31 as the decision boundary.
We included a summary of the model in the additional work section.\\

Finally we will assess the performance of our model using the test set
and the our test set accuracy is 0.8431, fpr is 0.2885 and fnr is 0.02.


\section{Discussion}
Overall our model seems to be performing reasonable well with an overal accuracy
around 0.85 and false negative rate (fnr) under 0.02 on the test sets.
The false positive rate (fpr) is relatively high at around 0.3,
but it is to be expected because our final threshold was chosen
to be biased for fnr.
However, one can argue that 0.02 fnr is still way too high for our purpose
and even more so for 0.05, which we chose to be our target fnr for the model.
We admit that our choice is not very well justified but without further guidance
from medical professionals, choosing a relatively low control rate seems
to be the best available option.\\


During feature engineering, we only consider interaction between 2 explanatory
variables because we realized using interaction between 3 or more variables
would lead the model to overfit the training data. The model achieves a very
high test accuracy (~0.97) but the test fnr would stay at 0.06 even
with a decision boundary as small as 0.01, which we believe indicates the model
overfitted the training data and wasn't able to distinguish a portion of positive
cases in test set. \\

Since our primary focus is on prediction, we will discuss the diagnostic plots
and model interpretations in the addition work section. \\


Going forward, there are several things we can do to improve our current model.
First, we can consult medical professionals to gather feedback on our choice
of specific parameters (e.g. target fnr at 0.05) and the field-specific
criteria/statistical tests used to evaluate models in medical research.
In addition, it would be helpful to assess if there's any potential bias
in our data set (e.g. are people of color not well represented)
by gathering more demographic information and adjust our model accordingly.
Last but not the least, we can use ANOVA test to detect if colinear terms are
present in our model to improve the stability of our model for better interpretability.\\

\section{Conclusion}
In conclusion, we believe that our model design tackles the challenges to control
fnr and model size well while maintaining a relatively high overall accuracy.
We recommend that this model should be used by medical professionals
in conjunction with their medical expertise as an indication
if more comprehensive tests are needed for people with potentially heart diseases
and doctors should refer to full model interpretation part in the additional work
section for guidance on how to interpret and use the model.\\



\section{Reference}
[1] Source of data: https://www.kaggle.com/johnsmith88/heart-disease-dataset \\



\section{Addtional Work}
\subsection{Further details on our final model}
\subsubsection{Summary of final model}

\input{derived_docs/summary_of_final_model.tex}\\


\subsubsection{Diagnostic Plots}

\includegraphics[width=1\textwidth]{figures/diagnostic_plots.png}\\

In residuals vs fitted, we observe the average roughly line up with y=0,
though we do observe some large negative residuals which is probably a
result of our choice to biased the model towards reducing false negatives.
The QQ plot follows a straight line for the most part but the trend disappeared
towards the left end where the negative residuals are, probably for the same
reason. In scale vs location, we observe some large residuals values as expected
after seeing the two previous plots. Interstingly, in all three plots, we observe
several points with a very large postive residuals and in the residuals vs leverage,
these points are shown to have very large leverages. We believe these points
represent patients who don't have heart disease but are very different from
other healthy patients as measured by the features in our model. These data
points are probably the cause of the overfitting of three-interaction-term model.
Therefore, it would be interesting to explore these influential points in our
future analysis.

\subsection{Other methods attempted}
Besides BIC, we attempted four other methods to perform variable selection
including forward AIC, R-squared, Mallow's CP, LASSO regularization and a custom
method we designed. Besides regression models, we also fitted a 10-layer decision
tree. For all the models mentioned above, we used the same method to determine
the optimal decision boundary as our final model: namely we use a fpr vs fnr
plot and find the boundary that would minimize fpr while keeping the fnr under
5\%. However, it should be noted that since LASSO and our custom method rely on
cross validation, we only split the dataset intro training (90\%) and test data
(10\% and no validation set). Therefore, the fpr vs fnr plot was constructed
using the fitted values on the training set instead of the predictions of the
validation set. However, we keep the same random seed to ensure our comparison
between different models are valid and fair.


\subsubsection{Mallow's CP}
We attempted Mallow's CP because Mallow's CP minimizes the model's residual \
deviance (which is equvalient with maximizing the likelihood of the data in most
cases and is closely associated with high accuracy) and therefore seems a valid
criteria to select the most helpful features.

\includegraphics[width=1\textwidth]{figures/mallow_roc.png}\\

For Mallow's CP, the decision boundary that maximizes te overall accuracy (0.33)
also keeps the fnr below 5\%.

When tested against the test set, the model achieves an amazing overall accuracy
of 92.16\%, fpr 13.46\% and fnr 2\%. Although the acccuracy and fpr were
signficantly improved without increasing the fnr compared to BIC, the Mallow's CP
selected 46 features and given such a huge model has no interpretability in the
medical practice, we decided not to use it even with its superior performance.

\subsubsection{Adjusted R-squared}
We attempted adjusted R-squared because adjusted R-squared directly minimizes
the model's residual deviance (which is equvalient with maximizing the
likelihood of the data in most cases and is closely associated with high
accuracy) while penalizing the larger models and therefore seems a valid
criteria for feature selection.

\includegraphics[width=1\textwidth]{figures/adjrsq_roc.png}\\

For adjusted R-squared, the decision boundary that maximizes te overall accuracy
(0.51) also keeps the fnr below 5\%.

When tested against the test set, the model also achieved an amazing overall
accuracy of 93.14\% and fpr 5.78\%, but the fnr is very high at 8\%. which is
higher than our control rate. Therefore, even though adjusted R-squared model
has a reasonable size (only 18 features in total) and higher accuracy, we
decided to not use it because of the high fnr.

\subsubsection{LASSO}
We also attempted to fit a LASSO regularized logistic model. LASSO can be a
valid method because it does feature selection implicitly by minimizing the
residual deviance (which is closely associated with high accuracy) while
penalizing large coefficients and forcing many small coefficients to 0. To find
the best beta (regularization parameter), we used 10-fold cross-validation.
Cross validation is a valid method to find beta because it finds the beta that
minimizes the overall residuan deviance.

\includegraphics[width=1\textwidth]{figures/lasso_roc.png}\\

For LASSO, the decision boundary that maximizes te overall accuracy (0.47) also
keeps the fnr below 5\%.

When tested against the test set, the model achieved the best peformance acrosss
all the models we attempted with an overall accuracy of 96.1\%,  fpr of 5.77\%
and the fnr of 2\%. In addition to outperforming our final model in all metrics,
the decisioon boundary is very close to 0.5, which means the model was able to
distinguish between positive cases and negative cases without relying on the
bias towards fnr we introduced by lowering the decision boudary in other models.
The diagnostic plots also reflected that as we are no long seeing the skewnessed
in residuals in our final model. However, the LASSO has a fatal flaw: it uses
84 out 93 features available and LASSO coefficients don't have an intuitive
interpretation. Moreover, having such a large model made us worry that the model
is overfitting for this specific dataset. It is possible that the dataset itself
is biased (e.g. most of white males/females) even though we couldn't confirm
this without further information. As such, we arrived at the conclusion that we
should keep BIC as our final method.


\subsubsection{Decision Tree}
In addition to the logitistic regression, we also fitted 10-layer decision tree.
Decision tree provides an intuitive interpretation, which is a huge advantage
for our purpose, and we limit our tree to 10 layers to avoid overfitting.

\includegraphics[width=1\textwidth]{figures/tree_roc.png}\\

For the 10-layer decision tree, the decision boundary that maximizes te overall
accuracy (0.37) also keeps the fnr below 5\%.

When tested against the test set, the model achieved a slightly better overall
accuracy of 86.27\% and fpr 21.15\%, but the fnr is very high at 6\%. which is
higher than our control rate. Therefore, even though the decision tree has the
best interpretability and higher overall accuracy, we choose our final model
over it because of the high fnr.

\subsubsection{Summary of Methods attempted}

\begin{table}[]
\begin{tabular}{llllll}
                   & Num features & Threshold & Test accuracy & Test FPR & Test FNR \\
AIC                & 92           & 0.01      & 0.971         & 0        & 0.06     \\
BIC                & 17           & 0.31      & 0.843         & 0.288    & 0.02     \\
Mallow's CP        & 48           & 0.33      & 0.922         & 0.135    & 0.02     \\
Adjusted R-squared & 18           & 0.31      & 0.902         & 0.115    & 0.08     \\
Lasso              & 84           & 0.47      & 0.961         & 0.058    & 0.02     \\
Decision Tree      & maxdepth=10  & 0.37      & 0.863         & 0.212    & 0.06
\end{tabular}
\end{table}

\end{document}













#
